{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 Linear Model Selection & Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Accuracy: least squares will tend to have low bias. If $n >> p$ then the least squares estimate will also have low variance and therefore perform well on test observations. If $n$ is not large then there could be a lot of variability in the least squares fit, which results in overfitting and poor predictions on future observations. If $p > n$ then the variance is infinite and the method cannot be used at all.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Subset Selection\n",
    "\n",
    "###### Best Subset Selection\n",
    "Fit a seperate least squares regression for each possible combination of the $p$ predictors. We will fit all the $p$ models that contain exactly one predictor, all:\n",
    "$$\\frac{p(p - 1)}{2}$$\n",
    "\n",
    "that contain exactly 2 predictors, and so on. Then we select the best model from all of these possible models. \n",
    "\n",
    "###### Algorithm \n",
    "- Let $M_0$ denote the null model, which contains no predictors (predicts sample mean for each observation).\n",
    "- For $k = 1, ..., p$\n",
    "    - Fit all (p choose k) models that contain exactly $k$ predictors\n",
    "    - Pick the best among these and call it $M_k$. Here best is defined as having the smallest RSS, or largest $R^2$.\n",
    "- Select a single best model from among the $M_0, ..., M_p$ using cross-validated prediction error, $C_p$, AIC, BIC, or adjusted $R^2$.\n",
    "\n",
    "It is best to use Best subset selection when $p < 40$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stepwise Selection\n",
    "\n",
    "###### Forward Stepwise Selection\n",
    "- Let $M_0$ denote the null model, which contains no predictors\n",
    "- For $k = 0, ..., p - 1$\n",
    "    - Consider all p - k models that augment the predictors in $M_k$ with one additional predictor\n",
    "    - Choose the best among these p - k models, and call it $M_{k + 1}$. Here the best is defined as having the smallest RSS or highest $R^2$.\n",
    "- Select a single best model from the $M_0, ..., M_p$ using cross-validation prediction error. \n",
    "\n",
    "Doing this we will end up with:\n",
    "$$\\frac{1 + p(p + 1)}{2}$$\n",
    "\n",
    "###### Backward Stepwise Selection\n",
    "-Let $M_0$ represent the full model with all of the predictors $p$.\n",
    "- For $k = p, p-1, ..., 1$\n",
    "    - Consider all $k$ models that contain all but one of the predictors in $M_k$ for a total of $k - 1$ predictors.\n",
    "    - Choose the best among these $k$ models and all it $M_{k - 1}$. Here best is defined as having the smallest RSS or $R^2$.\n",
    "- Select the best model from all models using cross-validation prediction error. \n",
    "\n",
    "Backward requires that the number of $p$ is smaller than $n$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $C_p$, AIC, BIC, Adjusted $R^2$\n",
    "$$C_p = \\frac{(RSS + 2d \\hat \\sigma^2)}{n}$$\n",
    "\n",
    "where $\\hat \\sigma^2$ is an estimate of the vsriance of the error $\\epsilon$ associated with each response measurement. Usually this is done using the full model. The penalty $2d \\hat \\sigma^2$ will increase as the number of predictors increase to adjust for the decrease in training RSS. \n",
    "\n",
    "$$AIC = \\frac{(RSS + 2d \\hat \\sigma^2)}{n \\hat \\sigma^2}$$\n",
    "\n",
    "is defined for a large class of models fit by maximum likelihood. It is important to note that Mallow's $C_p$ and AIC are proportional.\n",
    "\n",
    "$$BIC = \\frac{(RSS + log(n) d  \\hat \\sigma^2)}{n \\hat \\sigma^2}$$\n",
    "\n",
    "and BIC tends to take on a small value for a model with low test error (like AIC). BIC places a penalty for models with many variables and favors smaller models. \n",
    "\n",
    "$$Adjusted R^2 = 1 - \\frac{ \\frac{RSS}{(n - d - 1)} }{ \\frac{TSS}{(n - 1)} }$$\n",
    "\n",
    "and a model with a large Adjusted $R^2$ indicates a model with a small test error. This model will also only include the correct variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation and Cross-Validation\n",
    "These methods have a leg up over the above criterion simply because these make less assumptions and evaluate the error directly on the test data. \n",
    "\n",
    "###### One-Standard-Error Rule\n",
    "Calculate the standard error of the estimated test MSE for each model size, then select the smallest model for which the estimated test error is within one standard error of the lowest point on the curve. If a set of models appear to be equally good, it makes sense to just choose the simpler model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrinkage Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shrink the model coefficients toward 0 minimizes the variance.\n",
    "\n",
    "#### Ridge Regression\n",
    "The coefficient estimates $\\hat \\beta^R$ are the vales that minimize:\n",
    "$$\\sum_{i = 1}^n\\ (y_i - \\beta_0 - \\sum_{j = 1}^p\\ \\beta_j\\ x_{ij})^2 + \\lambda\\ \\sum_{j = 1}^p\\ \\beta_j^2\\ = RSS + \\lambda\\ \\sum_{j = 1}^p\\ \\beta_j^2$$\n",
    "\n",
    "where $\\lambda \\ge 0$ is a tuning parameter. The shrinkage parameter $\\lambda\\ \\sum_{j = 1}^p\\ \\beta_j^2$ is small when the coefficients $\\beta$ are near 0. When $\\lambda$ is 0 then the tuning parameter has no effect and the ridge regression will produce the least squares estimates. As $\\lambda -> \\infty$ the impact of this shrinkage parameter grows and the coefficient approaches 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
