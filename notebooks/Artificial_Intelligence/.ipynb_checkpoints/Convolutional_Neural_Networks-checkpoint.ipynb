{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing\n",
    "https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator( rescale         = 1.0 / 255,\n",
    "                                    shear_range     = 0.2,\n",
    "                                    zoom_range      = 0.2,\n",
    "                                    horizontal_flip = True )\n",
    "\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0 / 255 )\n",
    "\n",
    "train_set = train_datagen.flow_from_directory( r'C:\\Users\\andre\\Desktop\\GitHub\\Data\\training_set',\n",
    "                                               target_size = ( 64, 64 ),\n",
    "                                               batch_size  = 32,\n",
    "                                               class_mode  = 'binary' )\n",
    "\n",
    "test_set = test_datagen.flow_from_directory( r'C:\\Users\\andre\\Desktop\\GitHub\\Data\\test_set',\n",
    "                                             target_size = ( 64, 64 ),\n",
    "                                             batch_size  = 32,\n",
    "                                             class_mode  = 'binary' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add( Convolution2D( 32, ( 3, 3 ), input_shape = ( 64, 64, 3 ), activation = 'relu', data_format = 'channels_last' ) )\n",
    "classifier.add( MaxPooling2D( pool_size = ( 2, 2 ) ) )\n",
    "\n",
    "classifier.add( Convolution2D( 32, ( 3, 3 ), activation = 'relu', data_format = 'channels_last' ) )\n",
    "classifier.add( MaxPooling2D( pool_size = ( 2, 2 ) ) )\n",
    "\n",
    "classifier.add( Flatten() )\n",
    "classifier.add( Dense( units = 128, activation = 'relu' ) )\n",
    "classifier.add( Dense( units = 1, activation = 'sigmoid' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile( optimizer = 'adam', loss = 'binary_crossentropy', metrics = [ 'accuracy' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 58s 230ms/step - loss: 0.6816 - acc: 0.5941 - val_loss: 0.6218 - val_acc: 0.6480\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 56s 225ms/step - loss: 0.6048 - acc: 0.6707 - val_loss: 0.6133 - val_acc: 0.6690\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.5760 - acc: 0.6943 - val_loss: 0.5588 - val_acc: 0.7125\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 56s 225ms/step - loss: 0.5524 - acc: 0.7114 - val_loss: 0.5696 - val_acc: 0.7040\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 51s 206ms/step - loss: 0.5351 - acc: 0.7280 - val_loss: 0.5432 - val_acc: 0.7330\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.5183 - acc: 0.7436 - val_loss: 0.5274 - val_acc: 0.7345\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.5018 - acc: 0.7529 - val_loss: 0.5359 - val_acc: 0.7480\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 48s 191ms/step - loss: 0.4913 - acc: 0.7580 - val_loss: 0.5546 - val_acc: 0.7300\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.4796 - acc: 0.7697 - val_loss: 0.5287 - val_acc: 0.7410\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.4675 - acc: 0.7749 - val_loss: 0.5345 - val_acc: 0.7505\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.4647 - acc: 0.7767 - val_loss: 0.5097 - val_acc: 0.7660\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.4515 - acc: 0.7806 - val_loss: 0.5318 - val_acc: 0.7620\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.4391 - acc: 0.7936 - val_loss: 0.5514 - val_acc: 0.7355\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.4343 - acc: 0.7950 - val_loss: 0.5370 - val_acc: 0.7530\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.4271 - acc: 0.7979 - val_loss: 0.6420 - val_acc: 0.7130\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.4133 - acc: 0.8100 - val_loss: 0.5404 - val_acc: 0.7675\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.4053 - acc: 0.8108 - val_loss: 0.5260 - val_acc: 0.7745\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.4029 - acc: 0.8161 - val_loss: 0.5387 - val_acc: 0.7700\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.3929 - acc: 0.8214 - val_loss: 0.5769 - val_acc: 0.7510\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 48s 194ms/step - loss: 0.3780 - acc: 0.8288 - val_loss: 0.5548 - val_acc: 0.7695\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 51s 205ms/step - loss: 0.3710 - acc: 0.8341 - val_loss: 0.5577 - val_acc: 0.7675\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.3633 - acc: 0.8354 - val_loss: 0.5802 - val_acc: 0.7620\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 49s 198ms/step - loss: 0.3600 - acc: 0.8375 - val_loss: 0.5686 - val_acc: 0.7690\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 48s 194ms/step - loss: 0.3517 - acc: 0.8396 - val_loss: 0.6161 - val_acc: 0.7615\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 53s 214ms/step - loss: 0.3419 - acc: 0.8527 - val_loss: 0.6171 - val_acc: 0.7485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ab3fd42e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator( train_set,\n",
    "                          steps_per_epoch  = ( 8000 / 32 ),\n",
    "                          epochs           = 25,\n",
    "                          validation_data  = test_set,\n",
    "                          validation_steps = ( 2000 / 32 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img( r'C:\\Users\\andre\\Desktop\\GitHub\\Data\\single_prediction\\cat_or_dog_1.jpg', target_size = ( 64, 64 ) )\n",
    "test_image = image.img_to_array( test_image )\n",
    "test_image = np.expand_dims( test_image, axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict( test_image )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:\n",
    "    print( 'Dog' )\n",
    "else:\n",
    "    print( 'Cat' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img( r'C:\\Users\\andre\\Desktop\\GitHub\\Data\\single_prediction\\cat_or_dog_2.jpg', target_size = ( 64, 64 ) )\n",
    "test_image = image.img_to_array( test_image )\n",
    "test_image = np.expand_dims( test_image, axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict( test_image )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:\n",
    "    print( 'Dog' )\n",
    "else:\n",
    "    print( 'Cat' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
