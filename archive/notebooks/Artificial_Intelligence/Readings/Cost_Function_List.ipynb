{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A list of Cost Functions used in Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many layers of neurons connected together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_j^i$ is the activation (output) of the $j$th neuron in the $i$th layer, where $a_j^1$ is the $j$th element in the input vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relate next layer input to previous:\n",
    "$$a_j^i = \\sigma( \\sum_k\\ ( w_{jk}^i\\ dot\\ a_k^{i - 1} ) + b_j^i )$$\n",
    "\n",
    "where:\n",
    "- $\\sigma$ is the activation function\n",
    "- $w_{jk}^i$ is the weight for the $k$th neuron in the $(i - 1)$th layer to the $j$th neuron in the $i$th layer.\n",
    "- $b_j^i$ is the bias of the $j$th neuron in the $i$th layer\n",
    "- $a_j^i$ represents the activation value of the $j$th neuron in the $i$th layers.\n",
    "\n",
    "Sometimes we write $z_j^i$ to represent $\\sum_k\\ ( w_{jk}^i\\ dot\\ a_k^{i - 1} ) + b_j^i )$, in other words the activation value of a neuron before applying the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more concise notation:\n",
    "$$a_i = \\sigma( w_i x a^{i - 1} x b^i )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of $I$ as the inputs $\\in R^n$, and set $a^1 = I$ and the goal is to compute $a^1, ..., a^m$ where $m$ is the number of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function is a measure of how good a neural net did with respect to its given training sample and the expected output. This also depends on weights and biases. A cost function is a single value that evaluates how good the network did as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$C( W, B, S^r, E^r )$$\n",
    "\n",
    "where:\n",
    "- $W$ is the network's weights\n",
    "- $B$ is the network's biases\n",
    "- $S^r$ is the input of a single training sample\n",
    "- $E^r$ is the desired output of that training sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function:\n",
    "$$\\delta_j^L = \\frac{ \\partial\\ C }{ \\partial\\ \\alpha_j^L }\\ \\sigma'\\ ( z_i^j )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cost Function Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cost function must be written as an average: $C = \\frac{1}{n}\\ sum_x\\ C_x$\n",
    "- Cost function must not be dependent on any activation values of a neural network besides the output values $\\alpha^L$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Quadratic Costs\n",
    "$$C = \\frac{1}{2}\\ \\sum_j\\ ( a_j^L - E_j^r )^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cross-Entropy Cost\n",
    "$$C = \\sum_j\\ [ E_j^r\\ ln\\ \\alpha_j^L\\ + ( 1 - E_j^r )\\ ln\\ ( 1 - \\alpha_j^L ) ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exponential Cost\n",
    "$$C = t\\ exp( \\frac{ 1 }{ t }\\ \\sum_j\\ ( a_j^L - E_j^r )^2 )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hellinger DIstance\n",
    "$$C = \\frac{ 1 }{ \\sqrt( 2 ) }\\ \\sum_j\\ ( \\sqrt( \\alpha_j^L ) - \\sqrt( E_j^r ) )^2$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
