{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow        as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection             import train_test_split\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting C:Users\\andre\\Desktop\\GitHub\\Data\\MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting C:Users\\andre\\Desktop\\GitHub\\Data\\MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting C:Users\\andre\\Desktop\\GitHub\\Data\\MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting C:Users\\andre\\Desktop\\GitHub\\Data\\MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets( os.path.join( \"C:\", \"Users\", \"andre\", \"Desktop\", \"GitHub\", \"Data\", \"MNIST_data\" ), one_hot = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image = mnist.train.images[1].reshape( 28, 28 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c3810b3710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( single_image, cmap = 'gist_gray' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Steps\n",
    "\n",
    "- Placeholders \n",
    "- Variables\n",
    "- Create Graph Operations\n",
    "- Loss Function\n",
    "- Optimizer\n",
    "- Create Session\n",
    "- Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9214\n"
     ]
    }
   ],
   "source": [
    "x      = tf.placeholder( tf.float32, shape = [ None, 784 ] )\n",
    "y_true = tf.placeholder( tf.float32, shape = [ None, 10 ] )\n",
    "\n",
    "W = tf.Variable( tf.zeros( [ 784, 10 ] ) )\n",
    "b = tf.Variable( tf.zeros( [ 10 ] ) )\n",
    "\n",
    "y = tf.matmul( x, W ) + b\n",
    "\n",
    "cross_entropy = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2( labels = y_true, logits = y ) )\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer( learning_rate = 0.375 )\n",
    "train     = optimizer.minimize( cross_entropy )\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run( init )\n",
    "    \n",
    "    for step in range( 1000 ):\n",
    "        batch_x, batch_y = mnist.train.next_batch( 100 )\n",
    "        sess.run( train, feed_dict = { x : batch_x, y_true : batch_y } )\n",
    "        \n",
    "    correct_prediction = tf.equal( tf.argmax( y, axis = 1 ), tf.argmax( y_true, axis = 1 ) )\n",
    "    accuracy           = tf.reduce_mean( tf.cast( correct_prediction, tf.float32 ) )\n",
    "    \n",
    "    print( sess.run( accuracy, feed_dict = { x : mnist.test.images, y_true : mnist.test.labels } ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights( shape ):\n",
    "    init_random_dist = tf.truncated_normal( shape, stddev = 0.1 )\n",
    "    return tf.Variable( init_random_dist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias( shape ):\n",
    "    init_bias_vals = tf.constant( 0.1, shape = shape )\n",
    "    return tf.Variable( init_bias_vals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d( x, W ):\n",
    "    # x = [ batch, w, h, channels ]\n",
    "    # W = [ filter h, filter w, channels in, channels out ]\n",
    "    return tf.nn.conv2d( x, W, strides = [ 1, 1, 1, 1 ], padding = 'SAME' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2by2( x ):\n",
    "    # x = [ batch, h, w, channels ]\n",
    "    return tf.nn.max_pool( x, ksize = [ 1, 2, 2, 1 ], strides = [ 1, 2, 2, 1 ], padding = 'SAME' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer( input_x, shape ):\n",
    "    W = init_weights( shape )\n",
    "    b = init_bias( [ shape[ 3 ] ] )\n",
    "    \n",
    "    return tf.nn.relu( conv2d( input_x, W ) + b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_full_layer( input_layer, size ):\n",
    "    input_size = int( input_layer.get_shape()[1] )\n",
    "    W          = init_weights( [ input_size, size ] )\n",
    "    b          = init_bias( [ size ] )\n",
    "    \n",
    "    return tf.matmul( input_layer, W ) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:Users\\andre\\Desktop\\GitHub\\Data\\MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting C:Users\\andre\\Desktop\\GitHub\\Data\\MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting C:Users\\andre\\Desktop\\GitHub\\Data\\MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting C:Users\\andre\\Desktop\\GitHub\\Data\\MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets( os.path.join( \"C:\", \"Users\", \"andre\", \"Desktop\", \"GitHub\", \"Data\", \"MNIST_data\" ), one_hot = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON STEP: 0\n",
      "ACCURACY: \n",
      "0.1696\n",
      "\n",
      "\n",
      "ON STEP: 100\n",
      "ACCURACY: \n",
      "0.9373\n",
      "\n",
      "\n",
      "ON STEP: 200\n",
      "ACCURACY: \n",
      "0.9638\n",
      "\n",
      "\n",
      "ON STEP: 300\n",
      "ACCURACY: \n",
      "0.9671\n",
      "\n",
      "\n",
      "ON STEP: 400\n",
      "ACCURACY: \n",
      "0.9756\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x      = tf.placeholder( tf.float32, shape = [ None, 784 ] )\n",
    "y_true = tf.placeholder( tf.float32, shape = [ None, 10 ] )\n",
    "\n",
    "# -1 is essentially the None dimension\n",
    "x_image = tf.reshape( x, [ -1, 28, 28, 1 ] )\n",
    "\n",
    "# Compute 32 features for each 5x5 window\n",
    "convo_1      = convolutional_layer( x_image, shape = [ 5, 5, 1, 32 ] )\n",
    "convo_1_pool = max_pool_2by2( convo_1 )\n",
    "\n",
    "convo_2      = convolutional_layer( convo_1_pool, shape = [ 5, 5, 32, 64 ] )\n",
    "convo_2_pool = max_pool_2by2( convo_2 )\n",
    "\n",
    "convo_2_flat   = tf.reshape( convo_2_pool, [ -1, 7 * 7 * 64 ] )\n",
    "full_layer_one = tf.nn.relu( normal_full_layer( convo_2_flat, 1024 ) )\n",
    "\n",
    "hold_prob        = tf.placeholder( tf.float32 )\n",
    "full_one_dropout = tf.nn.dropout( full_layer_one, keep_prob = hold_prob )\n",
    "\n",
    "y_pred = normal_full_layer( full_one_dropout, 10 )\n",
    "\n",
    "cross_entropy = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2( labels = y_true, logits = y_pred ) )\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer( learning_rate = 0.001 )\n",
    "train     = optimizer.minimize( cross_entropy )\n",
    "\n",
    "init  = tf.global_variables_initializer()\n",
    "steps = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run( init )\n",
    "    \n",
    "    for step in range( steps ):\n",
    "        batch_x, batch_y = mnist.train.next_batch( 50 )\n",
    "        sess.run( train, feed_dict = { x         : batch_x, \n",
    "                                       y_true    : batch_y, \n",
    "                                       hold_prob : 0.5 } )\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print( \"ON STEP: {}\".format( step ) )\n",
    "            print( \"ACCURACY: \" )\n",
    "        \n",
    "            correct_prediction = tf.equal( tf.argmax( y_pred, axis = 1 ), tf.argmax( y_true, axis = 1 ) )\n",
    "            accuracy           = tf.reduce_mean( tf.cast( correct_prediction, tf.float32 ) )\n",
    "    \n",
    "            print( sess.run( accuracy, feed_dict = { x         : mnist.test.images, \n",
    "                                                     y_true    : mnist.test.labels, \n",
    "                                                     hold_prob : 1.0 } ) )\n",
    "            print( \"\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
